{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05_compute_ISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os.path import join as pjoin\n",
    "from os.path import isdir\n",
    "import os\n",
    "import mne_bids\n",
    "import mne\n",
    "from mne_bids import write_raw_bids, BIDSPath\n",
    "from scipy import stats\n",
    "import re\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "from scipy import signal, fftpack\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "sub_list = ['{0:0>2d}'.format(sub) for sub in np.arange(1,12)]\n",
    "run_list = ['{0:0>2d}'.format(run) for run in np.arange(1,9)]\n",
    "band_names = ['delta', 'theta', 'alpha', 'beta', 'gamma']\n",
    "\n",
    "# set path\n",
    "pre_root = '/nfs/e5/studyforrest/forrest_movie_meg/gump_meg_bids'\n",
    "post_root = pjoin(pre_root, 'derivatives', 'preproc_meg-mne_mri-fmriprep')\n",
    "\n",
    "results_pth = '/nfs/e5/studyforrest/forrest_movie_meg/tech_val_results/'\n",
    "if os.path.exists(results_pth) is False:\n",
    "    os.mkdir(results_pth)\n",
    "    \n",
    "power_data_dir = pjoin(results_pth, 'band_power')\n",
    "pre_powerdata_dir = pjoin(power_data_dir, 'pre')\n",
    "post_powerdata_dir = pjoin(power_data_dir, 'post')\n",
    "\n",
    "if os.path.exists(pre_powerdata_dir) is False:\n",
    "    os.makedirs(pre_powerdata_dir)\n",
    "if os.path.exists(post_powerdata_dir) is False:\n",
    "    os.makedirs(post_powerdata_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_megdata(bids_root, sub, run):\n",
    "\n",
    "    sub_path = BIDSPath(subject=sub, run=run, task='movie', session='movie', root=bids_root)\n",
    "    raw = mne_bids.read_raw_bids(sub_path)\n",
    "    \n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_events(bids_root, sub, run):\n",
    "    \n",
    "    raw = extract_megdata(bids_root, sub, run)\n",
    "    events = mne.find_events(raw, stim_channel='UPPT001', min_duration=2/raw.info['sfreq'])\n",
    "    \n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_picks(data):\n",
    "    # get valid channels\n",
    "    ch_name_picks = mne.pick_channels_regexp(data.ch_names, regexp='M[LRZ]...-4503')\n",
    "    type_picks = mne.pick_types(data.info, meg=True)\n",
    "    picks= np.intersect1d(ch_name_picks, type_picks)\n",
    "    return picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_split(raw, band_name):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    band_freq = {'delta': [1, 4],\n",
    "                 'theta': [4, 8],\n",
    "                 'alpha': [8, 13],\n",
    "                 'beta': [13, 30],\n",
    "                 'gamma': [30, 100]}\n",
    "    \n",
    "    raw_band = raw.copy().load_data().filter(l_freq=band_freq[band_name][0], h_freq=band_freq[band_name][1])\n",
    "\n",
    "    return raw_band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_isc(data1, data2):\n",
    "\n",
    "    \"\"\"calculate inter-subject correlation along the determined axis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "        data1, data2: array,\n",
    "            shape = [n_samples, n_features].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        isc: point-to-point functional connectivity list of\n",
    "            data1 and data2, shape = [n_samples].\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    data1 = np.nan_to_num(data1)\n",
    "    data2 = np.nan_to_num(data2)\n",
    "\n",
    "    z_data1 = np.nan_to_num(stats.zscore(data1, axis=-1))\n",
    "    z_data2 = np.nan_to_num(stats.zscore(data2, axis=-1))\n",
    "    corr = np.sum(z_data1*z_data2, axis=-1)/(np.size(data1, -1))\n",
    "\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_power_data(data_sub, events_sub, band_names, picks_ref):\n",
    "\n",
    "    picks_sub = get_picks(data_sub)\n",
    "    # match channels\n",
    "    picks = np.intersect1d(picks_sub, picks_ref)\n",
    "    \n",
    "    # mark bad channels\n",
    "    bad_idx = []\n",
    "    if len(picks) != len(picks_ref):\n",
    "        bad_picks = np.union1d(np.setdiff1d(picks_sub, picks_ref), np.setdiff1d(picks_ref, picks_sub))\n",
    "        for chn in bad_picks:\n",
    "            bad_idx.append(np.where(picks == chn)[0][0])\n",
    "    \n",
    "    power_data = {}\n",
    "    for band_name in band_names:\n",
    "        # band_split\n",
    "        band_sub = band_split(data_sub, band_name=band_name)\n",
    "        band_sub_data = band_sub.get_data(picks=picks)\n",
    "        # hilbert xfm\n",
    "        envlope = np.abs(signal.hilbert(band_sub_data))\n",
    "        if len(bad_idx) != 0:\n",
    "            for idx in bad_idx:\n",
    "                envlope[idx,:] = 0\n",
    "        # downsampling\n",
    "        envlope_dsamp = envlope.take(events_sub[1:-1:25,0], axis=1)\n",
    "        power_data[band_name] = envlope_dsamp\n",
    "    \n",
    "    del data_sub\n",
    "    \n",
    "    return power_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds directory : /nfs/e5/studyforrest/forrest_movie_meg/gump_meg_bids/sub-01/ses-movie/meg/sub-01_ses-movie_task-movie_run-01_meg.ds\n",
      "    res4 data read.\n",
      "    hc data read.\n",
      "    Separate EEG position data file read.\n",
      "    Quaternion matching (desired vs. transformed):\n",
      "       4.65   74.88    0.00 mm <->    4.65   74.88    0.00 mm (orig :  -65.68   46.24 -249.17 mm) diff =    0.000 mm\n",
      "      -4.65  -74.88    0.00 mm <->   -4.65  -74.88    0.00 mm (orig :   42.00  -58.24 -250.44 mm) diff =    0.000 mm\n",
      "      92.94    0.00    0.00 mm <->   92.94   -0.00    0.00 mm (orig :   46.46   62.07 -225.18 mm) diff =    0.000 mm\n",
      "    Coordinate transformations established.\n",
      "    Polhemus data for 3 HPI coils added\n",
      "    Device coordinate locations for 3 HPI coils added\n",
      "    Measurement info composed.\n",
      "Finding samples for /nfs/e5/studyforrest/forrest_movie_meg/gump_meg_bids/sub-01/ses-movie/meg/sub-01_ses-movie_task-movie_run-01_meg.ds/sub-01_ses-movie_task-movie_run-01_meg.meg4: \n",
      "    System clock channel is available, checking which samples are valid.\n",
      "    3 x 186000 = 558000 samples from 409 chs\n",
      "Current compensation grade : 3\n",
      "Reading events from /nfs/e5/studyforrest/forrest_movie_meg/gump_meg_bids/sub-01/ses-movie/meg/sub-01_ses-movie_task-movie_run-01_events.tsv.\n",
      "Reading channel info from /nfs/e5/studyforrest/forrest_movie_meg/gump_meg_bids/sub-01/ses-movie/meg/sub-01_ses-movie_task-movie_run-01_channels.tsv.\n"
     ]
    }
   ],
   "source": [
    "# get ref picks\n",
    "data_ref = extract_megdata(pre_root, '01', '01')\n",
    "picks_ref = get_picks(data_ref)\n",
    "del data_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute power data\n",
    "    \n",
    "for sub in sub_list:\n",
    "    if sub == '01':\n",
    "        run_ls = run_list + ['09']\n",
    "    else:\n",
    "        run_ls = run_list\n",
    "    \n",
    "    for run in run_ls:      \n",
    "        megdata = extract_megdata(pre_root, sub, run)\n",
    "        events = extract_events(pre_root, sub, run)\n",
    "        pre_power_data = get_power_data(megdata, events, band_names, picks_ref)\n",
    "        with open(pjoin(pre_powerdata_dir, 'sub-{0}_run-{1}.pickle'.format(sub, run)), 'wb') as fp:\n",
    "            pickle.dump(pre_power_data, fp)  \n",
    "            \n",
    "        megdata = extract_megdata(post_root, sub, run)\n",
    "        events = extract_events(post_root, sub, run)\n",
    "        post_power_data = get_power_data(megdata, events, band_names, picks_ref)\n",
    "        \n",
    "        with open(pjoin(post_powerdata_dir, 'sub-{0}_run-{1}.pickle'.format(sub, run)), 'wb') as fp:\n",
    "            pickle.dump(post_power_data, fp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bandISC(power_data_dir, sub_list, run_list, band_names, picks_ref):\n",
    "    \n",
    "    bandISC = {band_name : np.zeros((len(run_list), len(sub_list), len(sub_list), len(picks_ref)))\n",
    "               for band_name in band_names}\n",
    "    \n",
    "    for run in run_list:\n",
    "        if int(run) >= 7:\n",
    "            sub_ls = sub_list[1:]\n",
    "        else:\n",
    "            sub_ls = sub_list\n",
    "\n",
    "        # pair-wise ISC\n",
    "        for i, sub1 in enumerate(sub_ls):\n",
    "            with open(pjoin(power_data_dir, 'sub-{0}_run-{1}.pickle'.format(sub1, run)), 'rb') as fp:\n",
    "                powerdata_sub1 = pickle.load(fp) \n",
    "\n",
    "            for sub2 in sub_ls[i+1:]:\n",
    "                with open(pjoin(power_data_dir, 'sub-{0}_run-{1}.pickle'.format(sub2, run)), 'rb') as fp:\n",
    "                    powerdata_sub2 = pickle.load(fp) \n",
    "\n",
    "                for band_name in band_names:\n",
    "                    isc = compute_isc(powerdata_sub1[band_name], powerdata_sub2[band_name])\n",
    "                    bandISC[band_name][int(run)-1, int(sub1)-1, int(sub2)-1] = np.asarray(isc)\n",
    "                    \n",
    "        print( 'run ' + run + ' done')\n",
    "\n",
    "    return bandISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bandISC_leave1out(power_data_dir, sub_list, run_list, band_names, picks_ref):\n",
    "    \n",
    "    bandISC = {band_name : np.zeros((len(run_list), len(sub_list), len(picks_ref)))\n",
    "               for band_name in band_names}\n",
    "    \n",
    "    for run in run_list:\n",
    "        if int(run) >= 7:\n",
    "            sub_ls = sub_list[1:]\n",
    "        else:\n",
    "            sub_ls = sub_list\n",
    "\n",
    "        # sub-avg\n",
    "        sub_avg = {band_name : [] for band_name in band_names}\n",
    "        for sub in sub_ls:\n",
    "            with open(pjoin(power_data_dir, 'sub-{0}_run-{1}.pickle'.format(sub, run)), 'rb') as fp:\n",
    "                powerdata_sub = pickle.load(fp) \n",
    "            for band_name in band_names:\n",
    "                sub_avg[band_name].append(powerdata_sub[band_name])\n",
    "                \n",
    "        for band_name in band_names:\n",
    "            sub_avg[band_name] = np.asarray(sub_avg[band_name]).sum(0)\n",
    "        \n",
    "        # leave one out ISC\n",
    "        for sub in sub_ls:\n",
    "            with open(pjoin(power_data_dir, 'sub-{0}_run-{1}.pickle'.format(sub, run)), 'rb') as fp:\n",
    "                powerdata_sub = pickle.load(fp)\n",
    "            \n",
    "            for band_name in band_names:\n",
    "                leave1out_avg =  (sub_avg[band_name] - powerdata_sub[band_name]) / (len(sub_ls) - 1)\n",
    "                isc = compute_isc(powerdata_sub[band_name], leave1out_avg)\n",
    "                bandISC[band_name][int(run)-1, int(sub)-1] = np.asarray(isc)\n",
    "        \n",
    "        print( 'run ' + run + ' done')\n",
    "\n",
    "    return bandISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre\n",
    "bandISC_pre = compute_bandISC(pre_powerdata_dir, sub_list, run_list, band_names, picks_ref)\n",
    "with open(pjoin(results_pth, 'bandISC_pre.pickle'), 'wb') as fp:\n",
    "    pickle.dump(bandISC_pre, fp)  \n",
    "\n",
    "# post\n",
    "bandISC_post = compute_bandISC(post_powerdata_dir, sub_list, run_list, band_names, picks_ref)\n",
    "with open(pjoin(results_pth, 'bandISC_post.pickle'), 'wb') as fp:\n",
    "    pickle.dump(bandISC_post, fp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 01 done\n",
      "run 02 done\n",
      "run 03 done\n",
      "run 04 done\n",
      "run 05 done\n",
      "run 06 done\n",
      "run 07 done\n",
      "run 08 done\n",
      "run 01 done\n",
      "run 02 done\n",
      "run 03 done\n",
      "run 04 done\n",
      "run 05 done\n",
      "run 06 done\n",
      "run 07 done\n",
      "run 08 done\n"
     ]
    }
   ],
   "source": [
    "# pre\n",
    "bandISC_pre = compute_bandISC_leave1out(pre_powerdata_dir, sub_list, run_list, band_names, picks_ref)\n",
    "with open(pjoin(results_pth, 'bandISC_leave1out_pre.pickle'), 'wb') as fp:\n",
    "    pickle.dump(bandISC_pre, fp)  \n",
    "\n",
    "# post\n",
    "bandISC_post = compute_bandISC_leave1out(post_powerdata_dir, sub_list, run_list, band_names, picks_ref)\n",
    "with open(pjoin(results_pth, 'bandISC_leave1out_post.pickle'), 'wb') as fp:\n",
    "    pickle.dump(bandISC_post, fp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
